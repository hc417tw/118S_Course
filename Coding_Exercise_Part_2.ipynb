{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW3+nt+q00YtY7kDPrfcil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hc417tw/118S_Course/blob/main/Coding_Exercise_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTffNdP3duE6",
        "outputId": "9b9ce3a6-9cf3-412a-da86-3d8f540f598c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Churn Probability for new customer: 0.17\n",
            "Churn Prediction (1 = churn, 0 = no churn): 0\n",
            "\n",
            "Model Coefficients:\n",
            "Age: -0.116\n",
            "Usage Frequency: -0.610\n",
            "Support Calls: 0.799\n",
            "Total Spend: -0.291\n",
            "Last Interaction: -0.379\n",
            "Gender_Female: 0.581\n",
            "Gender_Male: -0.580\n",
            "Subscription Type_Basic: -0.097\n",
            "Subscription Type_Premium: -0.089\n",
            "Subscription Type_Standard: 0.186\n",
            " \n",
            "The chrun probability in the new customer list as the upon example shows is 0.17. This means there is 17% that the new customer would leave the business. This is relatively low risk, meaning the business can focus on customer who have have chrun proabiltiy. In addition, because 0.17 is less than 0.5 so the chrun prediction is 0\n",
            "The business can use the chrun probabiltiy to identify what kind of customer has higher chance to leave the business, since when customer left, the business might be harm. That's why model coefficents is important the data can make company acknowledge what customers has higher chance to leave. For example, user frequency for this dataset is -0.610, this means active users have lower chance to leave the busienss. Thereby, business can try to make user use their product more frequently.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Generate the data found on the Kaggle https://www.kaggle.com/datasets/sohailaelsayed/customer-churn\n",
        "data = {\n",
        "    'Age': [22, 41, 47, 35, 53, 30, 47, 54, 36, 65, 46, 56, 31, 42, 59, 35, 29, 45, 65, 62, 48, 36, 55, 36, 64, 65, 53, 41, 25, 44, 28, 34, 24, 27, 31, 46, 59, 56, 27, 42, 29, 36, 61, 57, 56, 42, 36, 37, 51, 57, 47, 29, 45, 18, 27, 23, 60, 57, 28, 64, 30, 18, 24, 40, 26, 41, 64, 42, 24, 52, 48, 28, 52, 52, 56, 64, 41, 48, 22, 42, 55, 43, 34, 27, 19, 58, 22, 22, 61, 28, 33, 37, 65, 22, 42, 36, 20, 58, 65, 40, 52, 35, 62, 41, 36, 39, 62, 55, 44, 39, 30, 41, 56, 24, 28, 46, 18, 34, 39, 32, 35, 40, 44, 52, 40, 41, 30, 64, 43, 31, 61, 56, 57, 41, 46, 65, 25, 43, 65, 25, 45, 20, 38, 43, 24, 56, 61, 38, 39, 29],\n",
        "    'Gender': ['Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Male', 'Male', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Female', 'Male', 'Female', 'Female', 'Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Female', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male'],\n",
        "    'Usage Frequency': [14, 28, 10, 12, 24, 14, 15, 11, 5, 4, 27, 23, 7, 27, 17, 3, 3, 30, 2, 19, 7, 4, 28, 20, 7, 7, 18, 7, 11, 7, 8, 3, 7, 8, 6, 10, 17, 15, 21, 10, 23, 24, 2, 26, 16, 14, 21, 26, 26, 30, 4, 5, 4, 21, 4, 20, 11, 28, 3, 25, 21, 16, 25, 7, 27, 4, 27, 2, 13, 8, 29, 20, 12, 26, 15, 9, 30, 12, 10, 25, 26, 16, 22, 22, 24, 10, 9, 10, 9, 19, 18, 21, 21, 27, 14, 18, 7, 28, 3, 26, 20, 23, 13, 27, 22, 29, 9, 15, 20, 30, 20, 11, 3, 3, 30, 10, 18, 7, 27, 12, 2, 4, 26, 10, 15, 27, 29, 17, 13, 23, 15, 7, 15, 20, 14, 17, 15, 11, 4, 7, 29, 10, 9, 20, 12, 20, 24, 13, 6, 8],\n",
        "    'Support Calls': [4, 7, 2, 5, 9, 10, 9, 0, 10, 2, 9, 5, 0, 5, 2, 7, 6, 4, 1, 2, 1, 0, 0, 4, 5, 3, 8, 7, 5, 8, 8, 0, 0, 1, 2, 4, 3, 8, 3, 9, 7, 5, 7, 5, 1, 8, 8, 2, 10, 2, 7, 0, 5, 3, 10, 3, 9, 3, 2, 2, 8, 10, 9, 0, 1, 6, 2, 7, 0, 9, 1, 1, 5, 5, 10, 7, 5, 0, 3, 5, 0, 6, 8, 3, 3, 5, 2, 10, 6, 10, 0, 6, 1, 9, 0, 8, 5, 10, 5, 10, 6, 4, 9, 4, 9, 5, 1, 1, 1, 3, 8, 9, 3, 8, 7, 0, 7, 8, 6, 8, 8, 0, 3, 2, 6, 1, 1, 4, 10, 2, 2, 0, 4, 0, 10, 10, 2, 3, 3, 5, 0, 5, 1, 10, 9, 6, 9, 2, 5, 8],\n",
        "    'Subscription Type': ['Basic', 'Standard', 'Premium', 'Premium', 'Standard', 'Premium', 'Basic', 'Standard', 'Basic', 'Basic', 'Standard', 'Basic', 'Premium', 'Premium', 'Premium', 'Basic', 'Basic', 'Basic', 'Premium', 'Premium', 'Premium', 'Premium', 'Standard', 'Basic', 'Basic', 'Premium', 'Basic', 'Premium', 'Premium', 'Basic', 'Basic', 'Basic', 'Standard', 'Premium', 'Standard', 'Standard', 'Basic', 'Standard', 'Premium', 'Basic', 'Basic', 'Premium', 'Premium', 'Premium', 'Premium', 'Basic', 'Basic', 'Basic', 'Basic', 'Standard', 'Standard', 'Standard', 'Standard', 'Premium', 'Premium', 'Basic', 'Standard', 'Premium', 'Premium', 'Standard', 'Standard', 'Basic', 'Premium', 'Standard', 'Basic', 'Standard', 'Basic', 'Premium', 'Premium', 'Premium', 'Standard', 'Basic', 'Basic', 'Standard', 'Standard', 'Premium', 'Basic', 'Basic', 'Standard', 'Premium', 'Premium', 'Basic', 'Premium', 'Basic', 'Basic', 'Basic', 'Basic', 'Premium', 'Standard', 'Premium', 'Premium', 'Premium', 'Premium', 'Standard', 'Premium', 'Premium', 'Basic', 'Basic', 'Standard', 'Basic', 'Standard', 'Standard', 'Standard', 'Basic', 'Standard', 'Basic', 'Standard', 'Standard', 'Basic', 'Basic', 'Premium', 'Premium', 'Standard', 'Basic', 'Basic', 'Basic', 'Standard', 'Premium', 'Basic', 'Basic', 'Basic', 'Basic', 'Basic', 'Basic', 'Basic', 'Premium', 'Standard', 'Standard', 'Standard', 'Premium', 'Premium', 'Premium', 'Basic', 'Standard', 'Basic', 'Basic', 'Basic', 'Standard', 'Basic', 'Basic', 'Standard', 'Premium', 'Premium', 'Basic', 'Basic', 'Basic', 'Premium', 'Premium', 'Premium', 'Premium'],\n",
        "    'Total Spend': [598, 584, 757, 232, 533, 500, 574, 323, 687, 995, 526, 187, 758, 438, 663, 677, 636, 127, 396, 202, 925, 463, 449, 373, 460, 166, 615, 696, 678, 792, 812, 156, 611, 943, 329, 493, 636, 384, 515, 820, 1000, 405, 879, 771, 600, 825, 231, 259, 244, 705, 136, 843, 402, 919, 699, 733, 563, 448, 172, 933, 576, 657, 843, 731, 665, 546, 579, 757, 515, 599, 554, 986, 844, 668, 867, 471, 628, 761, 599, 372, 213, 996, 403, 468, 368, 599, 759, 966, 784, 332, 364, 209, 428, 347, 418, 322, 920, 894, 570, 632, 442, 969, 719, 941, 218, 225, 345, 769, 717, 199, 821, 900, 175, 317, 600, 779, 635, 524, 382, 990, 532, 377, 486, 640, 104, 392, 255, 237, 555, 444, 630, 664, 186, 978, 996, 254, 123, 377, 921, 920, 335, 803, 888, 712, 257, 355, 201, 133, 910, 419],\n",
        "    'Last Interaction': [9, 20, 21, 18, 18, 29, 14, 16, 8, 10, 3, 1, 24, 30, 15, 25, 22, 18, 21, 24, 13, 26, 3, 25, 12, 1, 4, 20, 30, 27, 3, 15, 4, 12, 6, 1, 30, 6, 1, 17, 26, 4, 4, 4, 17, 19, 8, 15, 1, 5, 14, 6, 8, 3, 4, 1, 10, 12, 2, 9, 6, 26, 29, 27, 5, 26, 14, 25, 27, 20, 12, 19, 12, 3, 26, 11, 11, 8, 13, 8, 13, 17, 3, 25, 8, 25, 1, 7, 7, 24, 1, 29, 29, 11, 13, 10, 28, 28, 1, 5, 10, 7, 19, 18, 7, 27, 27, 30, 9, 13, 8, 14, 11, 3, 11, 23, 19, 1, 16, 21, 7, 7, 25, 3, 27, 3, 24, 5, 11, 2, 18, 27, 9, 11, 16, 1, 19, 9, 3, 22, 18, 15, 28, 2, 18, 12, 20, 24, 22, 27],\n",
        "    'Churn': [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "X = df[['Age', 'Gender', 'Usage Frequency','Support Calls', 'Subscription Type','Total Spend','Last Interaction']]\n",
        "y = df['Churn']\n",
        "numeric_features = ['Age', 'Usage Frequency', 'Support Calls', 'Total Spend', 'Last Interaction']\n",
        "categorical_features = ['Gender', 'Subscription Type']\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features) ])\n",
        "model = Pipeline(steps=[\n",
        "('preprocessor', preprocessor),\n",
        "('classifier', LogisticRegression(random_state=42))\n",
        "])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "new_customer = pd.DataFrame({\n",
        "'Age': [21],\n",
        "'Gender': ['Male'],\n",
        "'Support Calls': [0],\n",
        "'Subscription Type': ['Standard'],\n",
        "'Usage Frequency': [19],\n",
        "'Support Calls': [0],\n",
        "'Total Spend': [25],\n",
        "'Last Interaction': [0],\n",
        "})\n",
        "churn_probability = model.predict_proba(new_customer)[0][1]\n",
        "threshold = 0.5\n",
        "churn_prediction = 1 if churn_probability > threshold else 0\n",
        "feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
        "clean_feature_names = [name.split('__')[1] for name in feature_names]\n",
        "print(f\"Churn Probability for new customer: {churn_probability:.2f}\")\n",
        "print(f\"Churn Prediction (1 = churn, 0 = no churn): {churn_prediction}\")\n",
        "feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
        "coefficients = model.named_steps['classifier'].coef_[0]\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(clean_feature_names, coefficients):\n",
        "    print(f\"{feature}: {coef:.3f}\")\n",
        "print(\" \")\n",
        "print(\"The chrun probability in the new customer list as the upon example shows is 0.17. This means there is 17% that the new customer would leave the business. This is relatively low risk, meaning the business can focus on customer who have have chrun proabiltiy. In addition, because 0.17 is less than 0.5 so the chrun prediction is 0\")\n",
        "print(\"The business can use the chrun probabiltiy to identify what kind of customer has higher chance to leave the business, since when customer left, the business might be harm. That's why model coefficents is important the data can make company acknowledge what customers has higher chance to leave. For example, user frequency for this dataset is -0.610, this means active users have lower chance to leave the busienss. Thereby, business can try to make user use their product more frequently.\")\n"
      ]
    }
  ]
}